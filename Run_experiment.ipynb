{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "17xkFuf7o5gN9V9L9WkjuxbhmnHjQ65eL",
      "authorship_tag": "ABX9TyMzVe5fOsHP/g+HAG6Fu0c8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekaterinaKrupkina/decomposer_notebooks/blob/main/Run_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gjuqO0o3oD1x"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "import json\n",
        "from google.colab import userdata\n",
        "import shlex\n",
        "import pandas as pd\n",
        "import time\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up environment"
      ],
      "metadata": {
        "id": "rkkUUNdfK_Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /usr/local/*"
      ],
      "metadata": {
        "id": "IIYhcuOBDvo_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhWBFMKSpZsh",
        "outputId": "d22c8f43-4961-4a54-c077-a5e0ab1f7f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if not os.path.exists(\"/usr/local/venv-deployed\"):\n",
        "  !tar -xf /content/drive/MyDrive/HarmBench/venv.tar.gz -C /usr/local\n",
        "  !touch /usr/local/venv-deployed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kiTyXB3Li_H",
        "outputId": "7f7843e6-a5e1-47ca-9ecb-2b1ffaa92d10"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 470 ms, sys: 84.1 ms, total: 554 ms\n",
            "Wall time: 1min 30s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar -xf /content/drive/MyDrive/venv.tar.gz -C /usr/local"
      ],
      "metadata": {
        "id": "MaU16DWHoBFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/usr/local/lib/python3.10/site-packages')"
      ],
      "metadata": {
        "id": "0tGZ6WHTEorU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sFHccvD39nm",
        "outputId": "f4fb1d95-9f27-4904-ea10-f413e5d80be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python310.zip',\n",
              " '/usr/lib/python3.10',\n",
              " '/usr/lib/python3.10/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.10/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.10/dist-packages/IPython/extensions',\n",
              " '/root/.ipython']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## test code\n",
        "#import weave"
      ],
      "metadata": {
        "id": "TrwxG641QkUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x /usr/local/bin/pip\n"
      ],
      "metadata": {
        "id": "AIVugnG7HbD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"WANDB__EXECUTABLE\"] = \"/usr/local/bin/python\""
      ],
      "metadata": {
        "id": "q2FAuwIEEeMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"GITHUB_TOKEN\"] = userdata.get(\"GITHUB_TOKEN\")\n",
        "os.environ[\"OPENAI_BASE_URL\"] = \"https://api.openai.com/v1\"\n",
        "os.environ[\"MISTRAL_API_KEY\"] = userdata.get(\"MISTRAL_API_KEY\")"
      ],
      "metadata": {
        "id": "QyTyX4kbrg41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"HarmBench\"):\n",
        "  !git clone -q --recursive git@github.com:ekaterinaKrupkina/HarmBench\n",
        "%cd /content/HarmBench"
      ],
      "metadata": {
        "id": "pJELuReTQFX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"Decomposition-Harness\"):\n",
        "  !git clone https://{userdata.get(\"GITHUB_TOKEN\")}@github.com/PalisadeResearch/Decomposition-Harness"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOOoKEBXQkq9",
        "outputId": "69b19b01-1d8f-4938-e9bc-2fdf1b413eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Decomposition-Harness'...\n",
            "remote: Enumerating objects: 312, done.\u001b[K\n",
            "remote: Counting objects: 100% (94/94), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 312 (delta 57), reused 51 (delta 31), pack-reused 218\u001b[K\n",
            "Receiving objects: 100% (312/312), 923.51 KiB | 3.52 MiB/s, done.\n",
            "Resolving deltas: 100% (149/149), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import vllm"
      ],
      "metadata": {
        "id": "1gGbm7Or-FHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/HarmBench"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp7oyUfJsKU5",
        "outputId": "88acc033-261b-40e5-e5a7-f6339ea4d439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/HarmBench\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some important funcs"
      ],
      "metadata": {
        "id": "EPb_sAs-G-iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_in_background(script_path, output_file='output.log'):\n",
        "    \"\"\"\n",
        "    Run a Python script in the background and redirect its output to a file.\n",
        "\n",
        "    This function executes the specified Python script as a separate process,\n",
        "    allowing it to run independently of the calling process. The script's\n",
        "    standard output and standard error are redirected to the specified output file.\n",
        "\n",
        "    Parameters:\n",
        "    script_path (str): The path to the Python script to be executed.\n",
        "    output_file (str, optional): The path to the file where the script's output\n",
        "                                 will be written. Defaults to 'output.log'.\n",
        "\n",
        "    Returns:\n",
        "    int: The process ID (PID) of the newly created background process.\n",
        "\n",
        "    Notes:\n",
        "    - The function uses subprocess.Popen to create a new process.\n",
        "    - shlex.split is used to properly parse the command arguments.\n",
        "    - The script's stderr is redirected to stdout, which is then written to the output file.\n",
        "    - The process is set to run independently of the parent process using os.setsid.\n",
        "    - The function prints the PID of the new process to the console.\n",
        "\n",
        "    Raises:\n",
        "    subprocess.SubprocessError: If there's an error in creating or running the subprocess.\n",
        "    IOError: If there's an error in opening or writing to the output file.\n",
        "\n",
        "    Example:\n",
        "    >>> pid = run_in_background('/path/to/script.py', 'script_output.log')\n",
        "    >>> print(f\"Script is running in background with PID: {pid}\")\n",
        "    \"\"\"\n",
        "    # Construct the command\n",
        "    command = f\"python {script_path}\"\n",
        "\n",
        "    with open(output_file, 'a') as f:\n",
        "        process = subprocess.Popen(\n",
        "            shlex.split(command),  # Use shlex.split for proper argument parsing\n",
        "            stdout=f,\n",
        "            stderr=subprocess.STDOUT,  # Redirect stderr to stdout\n",
        "            preexec_fn=os.setsid  # This allows the process to run independently of the parent\n",
        "        )\n",
        "\n",
        "    print(f\"Process started with PID: {process.pid}\")\n",
        "    return process.pid"
      ],
      "metadata": {
        "id": "UvFyUm11bI5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_generate_completions(model_name, models_config_file, test_cases_path, save_path, behaviors_path):\n",
        "    \"\"\"\n",
        "    Run the generate_completions.py script as a subprocess.\n",
        "\n",
        "    This function executes the generate_completions.py script with the specified parameters,\n",
        "    captures its output in real-time, and prints it to the console.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name of the model to use for generating completions.\n",
        "        models_config_file (str): Path to the models configuration file.\n",
        "        test_cases_path (str): Path to the test cases file.\n",
        "        save_path (str): Path where the generated completions will be saved.\n",
        "        behaviors_path (str): Path to the behaviors dataset file.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        subprocess.CalledProcessError: If the subprocess returns a non-zero exit status.\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        \"python\", \"-u\", \"generate_completions.py\",\n",
        "        f\"--model_name={model_name}\",\n",
        "        f\"--models_config_file={models_config_file}\",\n",
        "        f\"--test_cases_path={test_cases_path}\",\n",
        "        f\"--save_path={save_path}\",\n",
        "        f\"--behaviors_path={behaviors_path}\"\n",
        "    ]\n",
        "\n",
        "    process = subprocess.Popen(\n",
        "        command,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    for line in process.stdout:\n",
        "        print(line, end='')\n",
        "\n",
        "    return_code = process.wait()\n",
        "\n",
        "    if return_code != 0:\n",
        "        print(f\"Process exited with return code {return_code}\")"
      ],
      "metadata": {
        "id": "dYLzjinGKbYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_evaluate_completions(behaviors_path, completions_path, save_path):\n",
        "    \"\"\"\n",
        "    Run the evaluate_completions.py script as a subprocess.\n",
        "\n",
        "    This function executes the evaluate_completions.py script with the specified parameters,\n",
        "    captures its output in real-time, and prints it to the console.\n",
        "\n",
        "    Args:\n",
        "        behaviors_path (str): Path to the behaviors dataset file.\n",
        "        completions_path (str): Path to the completions file to be evaluated.\n",
        "        save_path (str): Path where the evaluation results will be saved.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        subprocess.CalledProcessError: If the subprocess returns a non-zero exit status.\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        sys.executable,\n",
        "        \"-u\",\n",
        "        \"evaluate_completions.py\",\n",
        "        f\"--behaviors_path={behaviors_path}\",\n",
        "        f\"--completions_path={completions_path}\",\n",
        "        f\"--save_path={save_path}\"\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            command,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True\n",
        "        )\n",
        "\n",
        "        for line in process.stdout:\n",
        "            print(line, end='')\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error: {e}\")"
      ],
      "metadata": {
        "id": "u3aVz3NiHeRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment(experiment_params):\n",
        "    \"\"\"\n",
        "    Run a complete experiment pipeline including completion generation, evaluation, and result processing.\n",
        "\n",
        "    This function sets up the environment, runs the necessary scripts for generating completions\n",
        "    and evaluating them, and then processes and logs the results.\n",
        "\n",
        "    Args:\n",
        "        experiment_params (dict): A dictionary containing experiment parameters including model names.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    for k, v in experiment_params.items():\n",
        "        os.environ[k] = v\n",
        "\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = \"https://api.openai.com/v1\"\n",
        "    run_in_background(\"./Decomposition-Harness/server/web.py\", \"output.log\")\n",
        "\n",
        "    # TODO for Vladimir? create an empty file after initialization\n",
        "    #\n",
        "    time.sleep(10) # waiting for decomposer server initialization\n",
        "\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = \"http://127.0.0.1:8082\"\n",
        "\n",
        "    model_name = os.getenv(\"TARGET_MODEL\")\n",
        "    try:\n",
        "      run_generate_completions(\n",
        "          model_name=model_name,\n",
        "          models_config_file=\"./configs/model_configs/models.yaml\",\n",
        "          test_cases_path=\"./results/test_cases/test_cases_shortest.json\", # change to full\n",
        "          save_path=f\"./results/completions/completions_{model_name}.json\",\n",
        "          behaviors_path=\"./data/behavior_datasets/harmbench_behaviors_text_all.csv\"\n",
        "      )\n",
        "\n",
        "      run_evaluate_completions(\n",
        "          behaviors_path=\"./data/behavior_datasets/harmbench_behaviors_text_all.csv\",\n",
        "          completions_path=f\"./results/completions/completions_{model_name}.json\",\n",
        "          save_path=f\"./default/results/evaled_{model_name}.json\"\n",
        "      )\n",
        "\n",
        "      process_results(f\"./default/results/evaled_{model_name}\", decomposer=True)\n",
        "\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      pass\n",
        "\n",
        "\n",
        "\n",
        "    !pkill --full 'web\\.py'\n"
      ],
      "metadata": {
        "id": "hTsAkdLqJmB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment(experiment_params):\n",
        "    \"\"\"\n",
        "    Run a complete experiment pipeline including completion generation, evaluation, and result processing.\n",
        "\n",
        "    This function sets up the environment, runs the necessary scripts for generating completions\n",
        "    and evaluating them, and then processes and logs the results.\n",
        "\n",
        "    Args:\n",
        "        experiment_params (dict): A dictionary containing experiment parameters including model names.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    for k, v in experiment_params.items():\n",
        "        os.environ[k] = v\n",
        "\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = \"https://api.openai.com/v1\"\n",
        "    run_in_background(\"./Decomposition-Harness/server/web.py\", \"output.log\")\n",
        "    time.sleep(10)\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = \"http://127.0.0.1:8082\"\n",
        "\n",
        "    model_name = os.getenv(\"TARGET_MODEL\")\n",
        "\n",
        "    run_generate_completions(\n",
        "        model_name=model_name,\n",
        "        models_config_file=\"./configs/model_configs/models.yaml\",\n",
        "        test_cases_path=\"./results/test_cases/test_cases_short.json\",\n",
        "        save_path=f\"./results/completions/completions_{model_name}.json\",\n",
        "        behaviors_path=\"./data/behavior_datasets/harmbench_behaviors_text_all.csv\"\n",
        "    )\n",
        "\n",
        "    run_evaluate_completions(\n",
        "        behaviors_path=\"./data/behavior_datasets/harmbench_behaviors_text_all.csv\",\n",
        "        completions_path=f\"./results/completions/completions_{model_name}.json\",\n",
        "        save_path=f\"./default/results/evaled_{model_name}.json\"\n",
        "    )\n",
        "\n",
        "    #process_results(f\"evaled_{model_name}\", decomposer=True)\n",
        "\n",
        "    !pkill --full 'web\\.py'\n"
      ],
      "metadata": {
        "id": "lz7HZhtDnIEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's#API_TIMEOUT = 20#API_TIMEOUT = 600#' /content/drive/MyDrive/HarmBench/baselines/pair/language_models.py"
      ],
      "metadata": {
        "id": "yQcz6Cmrp2Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill --full 'web\\.py'"
      ],
      "metadata": {
        "id": "4FmBehEYUk3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/HarmBench"
      ],
      "metadata": {
        "id": "O34085U_Qddb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run experiments"
      ],
      "metadata": {
        "id": "UaeUP5r4SP7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_params = {\n",
        "    \"TARGET_MODEL\": \"gpt-4o-2024-05-13\",\n",
        "    \"COMPOSER_MODEL\": \"mistral-small-2312\",\n",
        "    \"DECOMPOSER_MODEL\": \"mistral-small-2312\",\n",
        "    \"SURROGATE_MODEL\": \"mistral-small-2312\"\n",
        "    }"
      ],
      "metadata": {
        "id": "VGNvTBMWLuaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment(experiment_params)"
      ],
      "metadata": {
        "id": "JDiL3gEbFJNk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "b3314372-d58b-4ae3-c855-5f275d840d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process started with PID: 10037\n",
            "Namespace(model_name='gpt-4o-2024-05-13', models_config_file='./configs/model_configs/models.yaml', behaviors_path='./data/behavior_datasets/harmbench_behaviors_text_all.csv', test_cases_path='./results/test_cases/test_cases_short.json', save_path='./results/completions/completions_gpt-4o-2024-05-13.json', max_new_tokens=256, generate_with_vllm=False, incremental_update=False)\n",
            "Warning: num_gpus in config (0) does not match num_gpus available (1). Using 1 GPUs.\n",
            "model_config {'model_name_or_path': 'gpt-4o', 'token': '<your_openai_token>', 'num_gpus': 1}\n",
            "Generating completions for 40 test cases\n",
            "Generating completions...\n",
            "\n",
            "  0%|          | 0/40 [00:00<?, ?it/s]<class 'openai.APIConnectionError'> Connection error.\n",
            "<class 'openai.APIConnectionError'> Connection error.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-0a578fea4e68>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-4d0ad5d48fd1>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(experiment_params)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TARGET_MODEL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     run_generate_completions(\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmodels_config_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./configs/model_configs/models.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-269deacde447>\u001b[0m in \u001b[0;36mrun_generate_completions\u001b[0;34m(model_name, models_config_file, test_cases_path, save_path, behaviors_path)\u001b[0m\n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1vn6d3VJnlyD"
      }
    }
  ]
}