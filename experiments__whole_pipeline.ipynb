{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekaterinaKrupkina/decomposer_notebooks/blob/main/experiments__whole_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjuqO0o3oD1x"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "import json\n",
        "from google.colab import userdata\n",
        "import shlex\n",
        "import pandas as pd\n",
        "import time\n",
        "import sys\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YMA8dlShXKe"
      },
      "source": [
        "TODO:\n",
        "\n",
        "\n",
        "1.   func to generate test cases\n",
        "2.   add asr to the summary table\n",
        "3.   think how to pass paths to the funcs\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkkUUNdfK_Gi"
      },
      "source": [
        "## Set up environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iufk8T9JLzVQ"
      },
      "source": [
        "## After installation you'll be asked to reload the runtime. Please, REFUSE\n",
        "\n",
        "It's WIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhWBFMKSpZsh",
        "outputId": "6a8c82d4-1c88-4323-a98d-b082c1ab7dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZF6m8okeFCR"
      },
      "outputs": [],
      "source": [
        "REQUIREMENTS_PATH = \"/content/drive/MyDrive/HarmBench/requirements_full.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "IFsB8TCkuXUL",
        "outputId": "f73ede14-5100-469c-bab6-9201bc37462e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wandb (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1))\n",
            "  Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/6.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m6.3/6.9 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (3.7.5)\n",
            "Requirement already satisfied: confection in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 3)) (0.1.5)\n",
            "Collecting vllm>=0.3.0 (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading vllm-0.5.1-cp310-cp310-manylinux1_x86_64.whl (146.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.9/146.9 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 5)) (4.41.2)\n",
            "Collecting fschat (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6))\n",
            "  Downloading fschat-0.2.36-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ray (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 7))\n",
            "  Downloading ray-2.32.0-cp310-cp310-manylinux2014_x86_64.whl (65.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai>=1.25.1 (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 8))\n",
            "  Downloading openai-1.35.13-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anthropic (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 9))\n",
            "  Downloading anthropic-0.31.0-py3-none-any.whl (865 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.4/865.4 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mistralai (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 10))\n",
            "  Downloading mistralai-0.4.2-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (0.5.4)\n",
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 12)) (1.57.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 13)) (0.18.0+cu121)\n",
            "Collecting sentence-transformers (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 14))\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 15)) (3.7.1)\n",
            "Collecting accelerate (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 16))\n",
            "  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasketch (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 17))\n",
            "  Downloading datasketch-1.6.5-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 18)) (2.0.3)\n",
            "Collecting art (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 19))\n",
            "  Downloading art-6.2-py3-none-any.whl (601 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.8/601.8 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 20)) (8.4.2)\n",
            "Collecting boto3 (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 21))\n",
            "  Downloading boto3-1.34.143-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bpe (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 22))\n",
            "  Downloading bpe-1.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting weave (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading weave-0.50.9-py3-none-any.whl (29.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.8/29.8 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-json-logger (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 24))\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1)) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1)) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1)) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1))\n",
            "  Downloading sentry_sdk-2.9.0-py2.py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (4.66.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (2.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (3.1.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: cmake>=3.21 in /usr/local/lib/python3.10/dist-packages (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (3.27.9)\n",
            "Collecting ninja (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (0.1.99)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (9.0.0)\n",
            "Collecting transformers (from -r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 5))\n",
            "  Downloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (0.19.1)\n",
            "Collecting fastapi (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (3.9.5)\n",
            "Collecting uvicorn[standard] (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (9.4.0)\n",
            "Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (0.20.0)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting tiktoken>=0.6.0 (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lm-format-enforcer==0.10.1 (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading lm_format_enforcer-0.10.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting outlines>=0.0.43 (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading outlines-0.0.46-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (4.12.2)\n",
            "Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (3.15.4)\n",
            "Collecting nvidia-ml-py (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading nvidia_ml_py-12.555.43-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (2.3.0+cu121)\n",
            "Collecting xformers==0.0.26.post1 (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting vllm-flash-attn==2.5.9 (from vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading vllm_flash_attn-2.5.9-cp310-cp310-manylinux1_x86_64.whl (37.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.1/37.1 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting interegular>=0.3.2 (from lm-format-enforcer==0.10.1->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 5)) (0.23.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 5)) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 5)) (0.4.3)\n",
            "Collecting httpx (from fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown2[all] (from fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6))\n",
            "  Downloading markdown2-2.5.0-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nh3 (from fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6))\n",
            "  Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.2/769.2 kB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6)) (3.0.47)\n",
            "Requirement already satisfied: rich>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6)) (13.7.1)\n",
            "Collecting shortuuid (from fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6))\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 7)) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 7)) (1.0.8)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.25.1->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.25.1->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 8)) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.25.1->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 8)) (1.3.1)\n",
            "Collecting jiter<1,>=0.4.0 (from anthropic->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 9))\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<3.11,>=3.9.10 (from mistralai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 10))\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m243.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (2.16.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (1.24.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 12)) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 12)) (3.21.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 12)) (1.12.3)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 12)) (2.0.4)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 12)) (0.16)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 14)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 14)) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 15)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 15)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 15)) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 15)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 15)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 18)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 18)) (2024.1)\n",
            "Collecting botocore<1.35.0,>=1.34.143 (from boto3->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 21))\n",
            "  Downloading botocore-1.34.143-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 21))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 21))\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bpe->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 22)) (3.8.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from bpe->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 22)) (7.4.4)\n",
            "Collecting hypothesis (from bpe->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 22))\n",
            "  Downloading hypothesis-6.106.0-py3-none-any.whl (463 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.3/463.3 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from bpe->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 22)) (0.12.1)\n",
            "Collecting mypy (from bpe->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 22))\n",
            "  Downloading mypy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23)) (14.0.2)\n",
            "Collecting aiofiles>=22.1.0 (from weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Collecting aioprocessing>=2.0.1 (from weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading aioprocessing-2.0.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23)) (3.0.3)\n",
            "Collecting janus>=1.0.0 (from weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading janus-1.0.0-py3-none-any.whl (6.9 kB)\n",
            "Collecting graphql-core>3 (from weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m150.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gql[requests]>=3.4.1 (from weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading gql-3.5.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting analytics-python>=1.2.9 (from weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading analytics_python-1.4.post1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting emoji>=2.12.1 (from weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from analytics-python>=1.2.9->weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23)) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from analytics-python>=1.2.9->weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff==1.10.0 (from analytics-python>=1.2.9->weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.25.1->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 8)) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.25.1->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 8)) (1.2.1)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.143->boto3->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 21)) (2.0.7)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (1.63.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 12)) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 12)) (2.7.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 12)) (0.13.1)\n",
            "INFO: pip is looking at multiple versions of gql[requests] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gql[requests]>=3.4.1 (from weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading gql-3.4.1-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting analytics-python>=1.2.9 (from weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
            "  Downloading analytics_python-1.3.1-py2.py3-none-any.whl (16 kB)\n",
            "  Downloading analytics_python-1.2.9-py2.py3-none-any.whl (13 kB)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql[requests]>=3.4.1->weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting requests-toolbelt<2,>=1.0.0 (from gql[requests]>=3.4.1->weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6)) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx->fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (1.2.0)\n",
            "Collecting lark (from outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading lark-1.1.9-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (2.2.1)\n",
            "Collecting diskcache (from outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (0.58.1)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (0.35.1)\n",
            "Collecting datasets (from outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycountry (from outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m117.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyairports (from outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading pyairports-2.1.1-py3-none-any.whl (371 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.7/371.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<1.0.0,>=0.30.0 (from prometheus-fastapi-instrumentator>=7.0.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3.0.0->fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6)) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (2.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6)) (2.16.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (0.7.11)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (1.5.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug>=3.0.3->weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23)) (2.1.5)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (4.1.1)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from hypothesis->bpe->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 22)) (2.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 7)) (2023.12.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 7)) (0.18.1)\n",
            "Collecting wavedrom (from markdown2[all]->fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6))\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting latex2mathml (from markdown2[all]->fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6))\n",
            "  Downloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=1.0.0 (from mypy->bpe->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 22))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy->bpe->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 22)) (2.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->bpe->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 22)) (1.4.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->bpe->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 22)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->bpe->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 22)) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 14)) (3.5.0)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 12)) (1.5.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 11)) (0.6.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 2)) (1.14.1)\n",
            "Collecting pyarrow>=14.0.1 (from weave->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 23))\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<3,>=2.0.0 (from wandb->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 1))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->outlines>=0.0.43->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (0.41.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->vllm>=0.3.0->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 4)) (1.3.0)\n",
            "Collecting svgwrite (from wavedrom->markdown2[all]->fschat->-r /content/drive/MyDrive/HarmBench/requirements_full.txt (line 6))\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: wavedrom\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30055 sha256=c20d8eb2f5ceebd0aa1d6703f1f918cedeeff53349a83337baac875ffba60685\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n",
            "Successfully built wavedrom\n",
            "Installing collected packages: pyairports, nvidia-ml-py, ninja, nh3, xxhash, websockets, uvloop, ujson, svgwrite, smmap, shortuuid, setproctitle, sentry-sdk, requests, python-multipart, python-json-logger, python-dotenv, pycountry, pyarrow, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, markdown2, latex2mathml, lark, jmespath, jiter, janus, interegular, hypothesis, httptools, h11, graphql-core, emoji, docker-pycreds, dnspython, diskcache, dill, backoff, art, aioprocessing, aiofiles, wavedrom, watchfiles, uvicorn, tiktoken, starlette, requests-toolbelt, nvidia-cusparse-cu12, nvidia-cudnn-cu12, mypy, multiprocess, httpcore, gql, gitdb, email_validator, datasketch, botocore, analytics-python, s3transfer, prometheus-fastapi-instrumentator, nvidia-cusolver-cu12, lm-format-enforcer, httpx, gitpython, bpe, wandb, transformers, ray, openai, mistralai, fastapi-cli, datasets, boto3, anthropic, xformers, weave, vllm-flash-attn, sentence-transformers, outlines, fastapi, accelerate, vllm, fschat\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.32.1 aiofiles-24.1.0 aioprocessing-2.0.1 analytics-python-1.2.9 anthropic-0.31.0 art-6.2 backoff-2.2.1 boto3-1.34.143 botocore-1.34.143 bpe-1.0 datasets-2.20.0 datasketch-1.6.5 dill-0.3.8 diskcache-5.6.3 dnspython-2.6.1 docker-pycreds-0.4.0 email_validator-2.2.0 emoji-2.12.1 fastapi-0.111.0 fastapi-cli-0.0.4 fschat-0.2.36 gitdb-4.0.11 gitpython-3.1.43 gql-3.5.0 graphql-core-3.2.3 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 hypothesis-6.106.0 interegular-0.3.3 janus-1.0.0 jiter-0.5.0 jmespath-1.0.1 lark-1.1.9 latex2mathml-3.77.0 lm-format-enforcer-0.10.1 markdown2-2.5.0 mistralai-0.4.2 multiprocess-0.70.16 mypy-1.10.1 mypy-extensions-1.0.0 nh3-0.2.18 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py-12.555.43 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 openai-1.35.13 orjson-3.10.6 outlines-0.0.46 prometheus-fastapi-instrumentator-7.0.0 pyairports-2.1.1 pyarrow-16.1.0 pycountry-24.6.1 python-dotenv-1.0.1 python-json-logger-2.0.7 python-multipart-0.0.9 ray-2.32.0 requests-2.32.3 requests-toolbelt-1.0.0 s3transfer-0.10.2 sentence-transformers-3.0.1 sentry-sdk-2.9.0 setproctitle-1.3.3 shortuuid-1.0.13 smmap-5.0.1 starlette-0.37.2 svgwrite-1.4.3 tiktoken-0.7.0 transformers-4.42.4 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 vllm-0.5.1 vllm-flash-attn-2.5.9 wandb-0.17.4 watchfiles-0.22.0 wavedrom-2.0.3.post3 weave-0.50.9 websockets-12.0 xformers-0.0.26.post1 xxhash-3.4.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "5b4c665aa23c407aa5d2ff3bf13f80f5",
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -r {REQUIREMENTS_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3WLPzYPmnwA",
        "outputId": "35be00de-ce6e-479f-f47f-0077776e06b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/HarmBench\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/HarmBench"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2FAuwIEEeMq"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB__EXECUTABLE\"] = \"/usr/local/bin/python\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyTyX4kbrg41"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"GITHUB_TOKEN\"] = userdata.get(\"GITHUB_TOKEN\")\n",
        "os.environ[\"OPENAI_BASE_URL\"] = \"https://api.openai.com/v1\"\n",
        "os.environ[\"MISTRAL_API_KEY\"] = userdata.get(\"MISTRAL_API_KEY\")\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJELuReTQFX6",
        "outputId": "bcf0abda-f0c5-453e-e668-a4a726044876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Host key verification failed.\r\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n",
            "[Errno 2] No such file or directory: '/content/HarmBench'\n",
            "/content/drive/MyDrive/HarmBench\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(\"HarmBench\"):\n",
        "  !git clone -q --recursive git@github.com:ekaterinaKrupkina/HarmBench\n",
        "%cd /content/HarmBench"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMSBsv7DwBS0"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/drive/MyDrive/HarmBench/Decomposition-Harness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOOoKEBXQkq9",
        "outputId": "d65ea44d-44af-4c86-e898-1ee580896684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Decomposition-Harness'...\n",
            "remote: Enumerating objects: 361, done.\u001b[K\n",
            "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 361 (delta 93), reused 79 (delta 47), pack-reused 218\u001b[K\n",
            "Receiving objects: 100% (361/361), 937.59 KiB | 10.53 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(\"Decomposition-Harness\"):\n",
        "  !git clone https://{userdata.get(\"GITHUB_TOKEN\")}@github.com/PalisadeResearch/Decomposition-Harness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPb_sAs-G-iw"
      },
      "source": [
        "## Some important funcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke2Socm7G6yl"
      },
      "outputs": [],
      "source": [
        "time_s = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvFyUm11bI5j"
      },
      "outputs": [],
      "source": [
        "def run_in_background(script_path, output_file='output.log'):\n",
        "    \"\"\"\n",
        "    Run a Python script in the background and redirect its output to a file.\n",
        "\n",
        "    This function executes the specified Python script as a separate process,\n",
        "    allowing it to run independently of the calling process. The script's\n",
        "    standard output and standard error are redirected to the specified output file.\n",
        "\n",
        "    Parameters:\n",
        "    script_path (str): The path to the Python script to be executed.\n",
        "    output_file (str, optional): The path to the file where the script's output\n",
        "                                 will be written. Defaults to 'output.log'.\n",
        "\n",
        "    Returns:\n",
        "    int: The process ID (PID) of the newly created background process.\n",
        "\n",
        "    Notes:\n",
        "    - The function uses subprocess.Popen to create a new process.\n",
        "    - shlex.split is used to properly parse the command arguments.\n",
        "    - The script's stderr is redirected to stdout, which is then written to the output file.\n",
        "    - The process is set to run independently of the parent process using os.setsid.\n",
        "    - The function prints the PID of the new process to the console.\n",
        "\n",
        "    Raises:\n",
        "    subprocess.SubprocessError: If there's an error in creating or running the subprocess.\n",
        "    IOError: If there's an error in opening or writing to the output file.\n",
        "\n",
        "    Example:\n",
        "    >>> pid = run_in_background('/path/to/script.py', 'script_output.log')\n",
        "    >>> print(f\"Script is running in background with PID: {pid}\")\n",
        "    \"\"\"\n",
        "    # Construct the command\n",
        "    command = f\"python {script_path}\"\n",
        "\n",
        "    with open(output_file, 'a') as f:\n",
        "        process = subprocess.Popen(\n",
        "            shlex.split(command),  # Use shlex.split for proper argument parsing\n",
        "            stdout=f,\n",
        "            stderr=subprocess.STDOUT,  # Redirect stderr to stdout\n",
        "            preexec_fn=os.setsid  # This allows the process to run independently of the parent\n",
        "        )\n",
        "\n",
        "    print(f\"Process started with PID: {process.pid}\")\n",
        "    return process.pid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYLzjinGKbYE"
      },
      "outputs": [],
      "source": [
        "def run_generate_completions(model_name, models_config_file, test_cases_path, save_path, behaviors_path):\n",
        "    \"\"\"\n",
        "    Run the generate_completions.py script as a subprocess.\n",
        "\n",
        "    This function executes the generate_completions.py script with the specified parameters,\n",
        "    captures its output in real-time, and prints it to the console.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name of the model to use for generating completions.\n",
        "        models_config_file (str): Path to the models configuration file.\n",
        "        test_cases_path (str): Path to the test cases file.\n",
        "        save_path (str): Path where the generated completions will be saved.\n",
        "        behaviors_path (str): Path to the behaviors dataset file.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        subprocess.CalledProcessError: If the subprocess returns a non-zero exit status.\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        \"python\", \"-u\", \"generate_completions.py\",\n",
        "        f\"--model_name={model_name}\",\n",
        "        f\"--models_config_file={models_config_file}\",\n",
        "        f\"--test_cases_path={test_cases_path}\",\n",
        "        f\"--save_path={save_path}\",\n",
        "        f\"--behaviors_path={behaviors_path}\"\n",
        "    ]\n",
        "\n",
        "    process = subprocess.Popen(\n",
        "        command,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    for line in process.stdout:\n",
        "        print(line, end='')\n",
        "\n",
        "    return_code = process.wait()\n",
        "\n",
        "    if return_code != 0:\n",
        "        print(f\"Process exited with return code {return_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3aVz3NiHeRD"
      },
      "outputs": [],
      "source": [
        "def run_evaluate_completions(behaviors_path, completions_path, save_path):\n",
        "    \"\"\"\n",
        "    Run the evaluate_completions.py script as a subprocess.\n",
        "\n",
        "    This function executes the evaluate_completions.py script with the specified parameters,\n",
        "    captures its output in real-time, and prints it to the console.\n",
        "\n",
        "    Args:\n",
        "        behaviors_path (str): Path to the behaviors dataset file.\n",
        "        completions_path (str): Path to the completions file to be evaluated.\n",
        "        save_path (str): Path where the evaluation results will be saved.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        subprocess.CalledProcessError: If the subprocess returns a non-zero exit status.\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        sys.executable,\n",
        "        \"-u\",\n",
        "        \"evaluate_completions.py\",\n",
        "        f\"--behaviors_path={behaviors_path}\",\n",
        "        f\"--completions_path={completions_path}\",\n",
        "        f\"--save_path={save_path}\"\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            command,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True\n",
        "        )\n",
        "\n",
        "        for line in process.stdout:\n",
        "            print(line, end='')\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTsAkdLqJmB5"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "def process_results(file, project, config_file='/content/drive/MyDrive/HarmBench/config.json', entity=\"palisaderesearch\"):\n",
        "    \"\"\"\n",
        "    Process the results of the evaluation and log them to Weights & Biases.\n",
        "\n",
        "    This function reads the evaluation results from a JSON file, creates a DataFrame,\n",
        "    and logs the results to Weights & Biases for tracking and visualization.\n",
        "\n",
        "    Args:\n",
        "        file (str): Name of the JSON file containing the evaluation results (without .json extension).\n",
        "        decomposer (bool): Flag indicating whether a decomposer was used in the experiment.\n",
        "        config_file (str): Path to the JSON config file to append to the run's config.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the JSON data\n",
        "    data_eval = pd.read_json(file)\n",
        "    data_summ = pd.read_json(\"/content/drive/MyDrive/HarmBench/summary.json\")\n",
        "\n",
        "    # Convert JSON data to DataFrame\n",
        "    df_evaled = pd.DataFrame([{\"category\": key, **value[0]} for key, value in data_eval.items()])\n",
        "    df = df_evaled.merge(data_summ, on='test_case', how='inner')\n",
        "\n",
        "    # Add additional columns\n",
        "    df[\"target_model\"] = os.getenv(\"MODEL_TARGET\")\n",
        "    df[\"decomposer_model\"] = os.getenv(\"MODEL_DECOMPOSER\")\n",
        "    df['composer_model'] = os.getenv(\"MODEL_COMPOSER\")\n",
        "    df[\"surrogate_model\"] = os.getenv(\"MODEL_SURROGATE\")\n",
        "    df[\"ASR\"] = df[\"label\"].mean()\n",
        "\n",
        "    # Remove duplicates\n",
        "    df = df.drop_duplicates(subset=['test_case'])\n",
        "\n",
        "    # Print the DataFrame\n",
        "    print(df.head())\n",
        "\n",
        "    # Initialize W&B run\n",
        "    run = wandb.init(\n",
        "        entity=entity,\n",
        "        project=project,\n",
        "        save_code=False,\n",
        "        name=f\"decomp_{os.getenv('MODEL_TARGET')}_{time_s}\"\n",
        "    )\n",
        "\n",
        "    # Load the config file and update run config\n",
        "    with open(config_file, 'r') as f:\n",
        "        config_data = json.load(f)\n",
        "        run.config.update(config_data)\n",
        "\n",
        "    # Log the DataFrame as a W&B Table\n",
        "    run.log({\"harmbench\": wandb.Table(dataframe=df)})\n",
        "    run.summary[\"harmbench_mean\"] = df[\"label\"].mean()\n",
        "    run.summary[\"target_model\"] = os.getenv(\"MODEL_TARGET\")\n",
        "\n",
        "    # Aggregate the specified columns\n",
        "    columns_to_aggregate = [\n",
        "        'tokens_surrogate', 'tokens_target', 'tokens_decomposer',\n",
        "        'tokens_composer', 'price_surrogate', 'price_target',\n",
        "        'price_decomposer', 'price_composer', \"tokens_total\", \"price_total\"\n",
        "    ]\n",
        "    aggregated_data = df[columns_to_aggregate].mean().reset_index()\n",
        "    aggregated_data.columns = ['Metric', 'Avg']\n",
        "\n",
        "    # Convert aggregated DataFrame to JSON\n",
        "    aggregated_json_path = '/content/aggregated_data.json'\n",
        "    aggregated_data.to_json(aggregated_json_path, orient='records', lines=True)\n",
        "\n",
        "    # Save the JSON file to W&B\n",
        "    wandb.save(aggregated_json_path)\n",
        "\n",
        "    # Finish the W&B run\n",
        "    run.finish()\n",
        "\n",
        "    # Print the aggregated DataFrame\n",
        "    print(aggregated_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz7HZhtDnIEr"
      },
      "outputs": [],
      "source": [
        "def experiment(experiment_params):\n",
        "    \"\"\"\n",
        "    Run a complete experiment pipeline including completion generation, evaluation, and result processing.\n",
        "\n",
        "    This function sets up the environment, runs the necessary scripts for generating completions\n",
        "    and evaluating them, and then processes and logs the results.\n",
        "\n",
        "    Args:\n",
        "        experiment_params (dict): A dictionary containing experiment parameters including model names.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # for k, v in os.environ.items():\n",
        "    #   print(k,v)\n",
        "    for k, v in experiment_params.items():\n",
        "        os.environ[k] = str(v)\n",
        "\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = \"https://api.openai.com/v1\"\n",
        "    run_in_background(\"./Decomposition-Harness/server/web.py\", \"output.log\")\n",
        "    os.environ[\"BADLLAMA_ENDPOINT_URL\"] = \"https://kdko1b8bau1a25bc.eu-west-1.aws.endpoints.huggingface.cloud\"\n",
        "\n",
        "\n",
        "    # TODO for Vladimir? create an empty file after initialization\n",
        "    #\n",
        "    time.sleep(10) # waiting for decomposer server initialization\n",
        "\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = \"http://127.0.0.1:8082\"\n",
        "\n",
        "\n",
        "    model_name = os.getenv(\"MODEL_TARGET\")\n",
        "    try:\n",
        "      run_generate_completions(\n",
        "          model_name=model_name,\n",
        "          models_config_file=\"./configs/model_configs/models.yaml\",\n",
        "          test_cases_path=\"./results/test_cases/test_cases.json\", # change to full\n",
        "          save_path=f\"./results/completions/completions_{model_name}_{time_s}.json\",\n",
        "          behaviors_path=\"./data/behavior_datasets/harmbench_behaviors_text_all.csv\"\n",
        "      )\n",
        "\n",
        "      run_evaluate_completions(\n",
        "          behaviors_path=\"./data/behavior_datasets/harmbench_behaviors_text_all.csv\",\n",
        "          completions_path=f\"./results/completions/completions_{model_name}_{time_s}.json\",\n",
        "          save_path=f\"./default/results/evaled_{model_name}_{time_s}.json\"\n",
        "      )\n",
        "\n",
        "      process_results(f\"./default/results/evaled_{model_name}_{time_s}.json\", project='test_db')\n",
        "\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      pass\n",
        "\n",
        "    for k, v in experiment_params.items():\n",
        "      del os.environ[k]\n",
        "\n",
        "\n",
        "\n",
        "    !pkill --full 'web\\.py'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUaS5P16hGSj"
      },
      "outputs": [],
      "source": [
        "def get_summary_table(number_of_runs, project_name, entity_name='palisaderesearch'):\n",
        "    api = wandb.Api()\n",
        "\n",
        "    # Get all runs for the specified project\n",
        "    runs = api.runs(f\"{entity_name}/{project_name}\")\n",
        "\n",
        "    # Sort runs by creation time (newest first)\n",
        "    sorted_runs = sorted(runs, key=lambda run: datetime.strptime(run.created_at, \"%Y-%m-%dT%H:%M:%S\"), reverse=True)\n",
        "\n",
        "    # Get the n newest run IDs\n",
        "    newest_run_ids = [run.id for run in sorted_runs[:number_of_runs]]\n",
        "\n",
        "    full_table = pd.DataFrame()\n",
        "\n",
        "    for run_id in newest_run_ids:\n",
        "        artifact_name = f\"run-{run_id}-harmbench:v0\"\n",
        "        artifact_full_name = f\"{entity_name}/{project_name}/{artifact_name}\"\n",
        "\n",
        "        try:\n",
        "            # Attempt to retrieve the artifact\n",
        "            artifact = api.artifact(artifact_full_name)\n",
        "            table = artifact.get(\"harmbench\")\n",
        "            df = pd.DataFrame(data=table.data, columns=table.columns)\n",
        "\n",
        "            # Aggregate the data\n",
        "            agg_cols = ['price_total', 'tokens_total', 'ASR']\n",
        "            group_by_cols = ['target_model', 'decomposer_model']\n",
        "            aggregated_df = df.groupby(group_by_cols)[agg_cols].mean().reset_index()\n",
        "\n",
        "            # Rename the columns\n",
        "            aggregated_df = aggregated_df.rename(columns={\n",
        "                'price_total': 'AVG_price',\n",
        "                'tokens_total': 'AVG_tokens'\n",
        "            })\n",
        "\n",
        "            # Add run_id column\n",
        "            aggregated_df['run_id'] = run_id\n",
        "\n",
        "            full_table = pd.concat([full_table, aggregated_df], ignore_index=True)\n",
        "\n",
        "        except wandb.errors.CommError:\n",
        "            print(f\"Artifact not found: {artifact_full_name}\")\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    with wandb.init(project=project_name, entity=entity_name, job_type=\"summary_table\") as run:\n",
        "        # Log the summary table\n",
        "        run.log({\"summary_table\": wandb.Table(dataframe=full_table)})\n",
        "\n",
        "    # Print the resulting table\n",
        "    print(\"Summary Table:\")\n",
        "    print(full_table)\n",
        "\n",
        "    return full_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FmBehEYUk3E"
      },
      "outputs": [],
      "source": [
        "!pkill --full 'web\\.py'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaeUP5r4SP7f"
      },
      "source": [
        "## Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGNvTBMWLuaP"
      },
      "outputs": [],
      "source": [
        "\n",
        "experiment_params = {\n",
        "    \"TARGET_MODEL\": \"gpt-4o-2024-05-13\",\n",
        "    \"COMPOSER_MODEL\": \"gpt-3.5-turbo-1106\",\n",
        "    \"DECOMPOSER_MODEL\": \"gpt-3.5-turbo-1106\",\n",
        "    \"SURROGATE_MODEL\": \"gpt-3.5-turbo-1106\"\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0VAX1mtiw5V"
      },
      "outputs": [],
      "source": [
        "# experiments_dict = {\n",
        "#  \"decomposer_base\":{\n",
        "#     \"TARGET_MODEL\": \"gpt-4o-2024-05-13\",\n",
        "#     \"COMPOSER_MODEL\": \"gpt-3.5-turbo-1106\",\n",
        "#     \"DECOMPOSER_MODEL\": \"gpt-3.5-turbo-1106\",\n",
        "#     \"SURROGATE_MODEL\": \"gpt-3.5-turbo-1106\"\n",
        "#     },\n",
        "#  \"target_only_base\":{\n",
        "#     \"TARGET_MODEL\": \"gpt-4o-2024-05-13\",\n",
        "#     \"DECOMPOSER_MODEL\":\"\",\n",
        "#     \"MAX_QUERY_RETRIES_TARGET\":1\n",
        "#  }\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0L1NAs58kyY"
      },
      "outputs": [],
      "source": [
        "# decomposer: mistral, composer: gpt-3\n",
        "# decompoesr: gpt-3, composer: gpt-3\n",
        "# decomposer: badllama, composer: badllama\n",
        "# всё повторить на gpt3 и gpt-4o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9ynz13s_lkx",
        "outputId": "11755601-9bad-4330-92ed-f9f14623618e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exp2: {'MODEL_TARGET': 'gpt-4o-2024-05-13', 'MODEL_COMPOSER': 'gpt-3.5-turbo-1106', 'MODEL_DECOMPOSER': 'gpt-3.5-turbo-1106', 'MODEL_SURROGATE': 'gpt-3.5-turbo-1106'}\n",
            "exp3: {'MODEL_TARGET': 'gpt-4o-2024-05-13', 'MODEL_COMPOSER': 'badllama', 'MODEL_DECOMPOSER': 'badllama', 'MODEL_SURROGATE': 'gpt-3.5-turbo-1106'}\n"
          ]
        }
      ],
      "source": [
        "experiments_dict = {\n",
        "    #gpt-4o as target model\n",
        "    # \"exp1\": {\n",
        "    #     \"MODEL_TARGET\": \"gpt-4o-2024-05-13\",\n",
        "    #     \"MODEL_COMPOSER\": \"gpt-3.5-turbo-1106\",\n",
        "    #     \"MODEL_DECOMPOSER\": \"mistral-medium\",\n",
        "    #     \"MODEL_SURROGATE\": \"gpt-3.5-turbo-1106\"\n",
        "    # },\n",
        "    \"exp2\": {\n",
        "        \"MODEL_TARGET\": \"gpt-4o-2024-05-13\",\n",
        "        \"MODEL_COMPOSER\": \"gpt-3.5-turbo-1106\",\n",
        "        \"MODEL_DECOMPOSER\": \"gpt-3.5-turbo-1106\",\n",
        "        \"MODEL_SURROGATE\": \"gpt-3.5-turbo-1106\"\n",
        "    },\n",
        "    \"exp3\": {\n",
        "        \"MODEL_TARGET\": \"gpt-4o-2024-05-13\",\n",
        "        \"MODEL_COMPOSER\": \"badllama\",\n",
        "        \"MODEL_DECOMPOSER\": \"badllama\",\n",
        "        \"MODEL_SURROGATE\": \"gpt-3.5-turbo-1106\"\n",
        "    },\n",
        "    # #gpt-3.5-turbo-1106 as target model\n",
        "    # \"exp4\": {\n",
        "    #     \"MODEL_TARGET\": \"gpt-3.5-turbo-1106\",\n",
        "    #     \"MODEL_COMPOSER\": \"gpt-3.5-turbo-1106\",\n",
        "    #     \"MODEL_DECOMPOSER\": \"Mistral 7B\",\n",
        "    #     \"MODEL_SURROGATE\": \"gpt-3.5-turbo-1106\"\n",
        "    # },\n",
        "    # \"exp5\": {\n",
        "    #     \"MODEL_TARGET\": \"gpt-3.5-turbo-1106\",\n",
        "    #     \"MODEL_COMPOSER\": \"gpt-3.5-turbo-1106\",\n",
        "    #     \"MODEL_DECOMPOSER\": \"gpt-3.5-turbo-1106\",\n",
        "    #     \"MODEL_SURROGATE\": \"gpt-3.5-turbo-1106\"\n",
        "    # },\n",
        "    # \"exp6\": {\n",
        "    #     \"MODEL_TARGET\": \"gpt-3.5-turbo-1106\",\n",
        "    #     \"MODEL_COMPOSER\": \"badllama\",\n",
        "    #     \"MODEL_DECOMPOSER\": \"badllama\",\n",
        "    #     \"MODEL_SURROGATE\": \"gpt-3.5-turbo-1106\"\n",
        "    # },\n",
        "    # # gpt-4o as target model, no decomposer\n",
        "    # \"exp7\": {\n",
        "    #     \"MODEL_TARGET\": \"gpt-4o-2024-05-13\",\n",
        "    #     \"MODEL_DECOMPOSER\": \"\",\n",
        "    #     \"MAX_QUERY_RETRIES_TARGET\": 1\n",
        "    # },\n",
        "    # # gpt-3.5-turbo-1106 as target model, no decomposer\n",
        "    # \"exp8\": {\n",
        "    #     \"MODEL_TARGET\": \"gpt-3.5-turbo-1106\",\n",
        "    #     \"MODEL_DECOMPOSER\": \"\",\n",
        "    #     \"MAX_QUERY_RETRIES_TARGET\": 1\n",
        "    # }\n",
        "}\n",
        "\n",
        "# Print the updated dictionary to verify\n",
        "for exp, params in experiments_dict.items():\n",
        "    print(f\"{exp}: {params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZsFWcKAiPDM",
        "outputId": "de194be4-8b80-4fca-959c-fdec4fcf7d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exp2\n",
            "Process started with PID: 7192\n",
            "2024-07-12 07:37:26.247433: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-07-12 07:37:26.299746: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-12 07:37:26.299802: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-12 07:37:26.301531: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-12 07:37:26.309185: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-12 07:37:27.495284: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Namespace(model_name='gpt-4o-2024-05-13', models_config_file='./configs/model_configs/models.yaml', behaviors_path='./data/behavior_datasets/harmbench_behaviors_text_all.csv', test_cases_path='./results/test_cases/test_cases.json', save_path='./results/completions/completions_gpt-4o-2024-05-13_2024-07-12_07-18-18.json', max_new_tokens=256, generate_with_vllm=False, incremental_update=False)\n",
            "Warning: num_gpus in config (0) does not match num_gpus available (1). Using 1 GPUs.\n",
            "model_config {'model_name_or_path': 'gpt-4o', 'token': '<your_openai_token>', 'num_gpus': 1}\n",
            "Generating completions for 400 test cases\n",
            "Generating completions...\n",
            "\n",
            "  0%|          | 0/400 [00:00<?, ?it/s]\n",
            "  0%|          | 1/400 [00:40<4:31:41, 40.86s/it]\n",
            "  0%|          | 2/400 [00:59<3:03:10, 27.61s/it]\n",
            "  1%|          | 3/400 [01:19<2:40:45, 24.30s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "  1%|          | 4/400 [11:56<29:16:12, 266.09s/it]\n",
            "  1%|▏         | 5/400 [12:16<19:27:23, 177.32s/it]\n",
            "  2%|▏         | 6/400 [13:12<14:53:16, 136.03s/it]\n",
            "  2%|▏         | 7/400 [13:59<11:40:37, 106.97s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "  2%|▏         | 8/400 [18:12<16:43:28, 153.59s/it]\n",
            "  2%|▏         | 9/400 [18:31<12:07:13, 111.59s/it]\n",
            "  2%|▎         | 10/400 [18:52<9:03:43, 83.65s/it] \n",
            "  3%|▎         | 11/400 [19:33<7:35:49, 70.31s/it]\n",
            "  3%|▎         | 12/400 [20:23<6:55:23, 64.23s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "  3%|▎         | 13/400 [36:29<36:16:28, 337.44s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "  4%|▎         | 14/400 [40:39<33:20:28, 310.95s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "  4%|▍         | 15/400 [56:45<54:23:18, 508.57s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "  4%|▍         | 16/400 [1:07:02<57:43:06, 541.11s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "  4%|▍         | 17/400 [1:10:52<47:37:29, 447.65s/it]\n",
            "  4%|▍         | 18/400 [1:12:38<36:35:44, 344.88s/it]\n",
            "  5%|▍         | 19/400 [1:12:58<26:10:13, 247.28s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "  5%|▌         | 20/400 [1:29:04<48:52:55, 463.09s/it]\n",
            "  5%|▌         | 21/400 [1:30:56<37:39:13, 357.66s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "  6%|▌         | 22/400 [1:47:02<56:44:24, 540.38s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "  6%|▌         | 23/400 [1:54:52<54:21:45, 519.11s/it]\n",
            "  6%|▌         | 24/400 [1:55:12<38:34:29, 369.33s/it]\n",
            "  6%|▋         | 25/400 [1:55:30<27:29:48, 263.97s/it]\n",
            "  6%|▋         | 26/400 [1:56:29<21:01:47, 202.43s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "  7%|▋         | 27/400 [2:00:42<22:33:06, 217.66s/it]\n",
            "  7%|▋         | 28/400 [2:03:44<21:22:27, 206.85s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "  7%|▋         | 29/400 [2:19:51<44:49:30, 434.96s/it]\n",
            "  8%|▊         | 30/400 [2:21:29<34:18:47, 333.86s/it]\n",
            "  8%|▊         | 31/400 [2:22:03<25:00:38, 244.01s/it]\n",
            "  8%|▊         | 32/400 [2:22:31<18:18:29, 179.10s/it]\n",
            "  8%|▊         | 33/400 [2:23:00<13:40:21, 134.12s/it]\n",
            "  8%|▊         | 34/400 [2:23:33<10:32:41, 103.72s/it]\n",
            "  9%|▉         | 35/400 [2:24:15<8:39:44, 85.44s/it]  \n",
            "  9%|▉         | 36/400 [2:25:01<7:26:09, 73.54s/it]\n",
            "  9%|▉         | 37/400 [2:25:32<6:07:11, 60.69s/it]\n",
            " 10%|▉         | 38/400 [2:26:09<5:22:38, 53.48s/it]\n",
            " 10%|▉         | 39/400 [2:26:44<4:48:57, 48.03s/it]\n",
            " 10%|█         | 40/400 [2:27:23<4:31:54, 45.32s/it]\n",
            " 10%|█         | 41/400 [2:27:57<4:10:47, 41.92s/it]\n",
            " 10%|█         | 42/400 [2:28:20<3:36:27, 36.28s/it]\n",
            " 11%|█         | 43/400 [2:31:22<7:56:23, 80.06s/it]\n",
            " 11%|█         | 44/400 [2:32:21<7:16:38, 73.59s/it]\n",
            " 11%|█▏        | 45/400 [2:32:59<6:12:44, 63.00s/it]\n",
            " 12%|█▏        | 46/400 [2:33:31<5:16:19, 53.61s/it]\n",
            " 12%|█▏        | 47/400 [2:34:06<4:43:12, 48.14s/it]\n",
            " 12%|█▏        | 48/400 [2:34:40<4:17:21, 43.87s/it]\n",
            " 12%|█▏        | 49/400 [2:35:18<4:06:33, 42.15s/it]\n",
            " 12%|█▎        | 50/400 [2:35:42<3:34:46, 36.82s/it]\n",
            " 13%|█▎        | 51/400 [2:36:18<3:31:27, 36.35s/it]\n",
            " 13%|█▎        | 52/400 [2:36:53<3:29:00, 36.04s/it]\n",
            " 13%|█▎        | 53/400 [2:37:27<3:24:30, 35.36s/it]\n",
            " 14%|█▎        | 54/400 [2:38:04<3:27:41, 36.02s/it]\n",
            " 14%|█▍        | 55/400 [2:38:40<3:25:35, 35.76s/it]\n",
            " 14%|█▍        | 56/400 [2:39:01<3:00:10, 31.43s/it]\n",
            " 14%|█▍        | 57/400 [2:39:20<2:37:51, 27.61s/it]\n",
            " 14%|█▍        | 58/400 [2:39:40<2:24:26, 25.34s/it]\n",
            " 15%|█▍        | 59/400 [2:39:58<2:12:16, 23.27s/it]\n",
            " 15%|█▌        | 60/400 [2:40:28<2:23:49, 25.38s/it]\n",
            " 15%|█▌        | 61/400 [2:41:15<3:00:00, 31.86s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            " 16%|█▌        | 62/400 [2:45:11<8:44:00, 93.02s/it]\n",
            " 16%|█▌        | 63/400 [2:45:41<6:56:06, 74.08s/it]\n",
            " 16%|█▌        | 64/400 [2:46:05<5:31:05, 59.12s/it]\n",
            " 16%|█▋        | 65/400 [2:47:27<6:07:33, 65.83s/it]\n",
            " 16%|█▋        | 66/400 [2:48:10<5:28:48, 59.07s/it]\n",
            " 17%|█▋        | 67/400 [2:48:49<4:55:06, 53.17s/it]\n",
            " 17%|█▋        | 68/400 [2:49:48<5:02:47, 54.72s/it]\n",
            " 17%|█▋        | 69/400 [2:50:07<4:03:11, 44.08s/it]\n",
            " 18%|█▊        | 70/400 [2:50:33<3:32:01, 38.55s/it]\n",
            " 18%|█▊        | 71/400 [2:51:21<3:48:20, 41.64s/it]\n",
            " 18%|█▊        | 72/400 [2:51:53<3:30:51, 38.57s/it]\n",
            " 18%|█▊        | 73/400 [2:52:24<3:18:26, 36.41s/it]\n",
            " 18%|█▊        | 74/400 [2:53:22<3:52:42, 42.83s/it]\n",
            " 19%|█▉        | 75/400 [2:54:01<3:45:01, 41.54s/it]\n",
            " 19%|█▉        | 76/400 [2:54:43<3:44:59, 41.67s/it]\n",
            " 19%|█▉        | 77/400 [2:55:02<3:09:14, 35.15s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            " 20%|█▉        | 78/400 [2:58:40<8:02:11, 89.85s/it]\n",
            " 20%|█▉        | 79/400 [3:01:12<9:39:50, 108.38s/it]\n",
            " 20%|██        | 80/400 [3:01:44<7:35:47, 85.46s/it] \n",
            " 20%|██        | 81/400 [3:02:17<6:11:18, 69.84s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            " 20%|██        | 82/400 [3:18:23<29:55:33, 338.78s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            " 21%|██        | 83/400 [3:34:10<45:53:57, 521.25s/it]\n",
            " 21%|██        | 84/400 [3:34:44<32:55:07, 375.03s/it]\n",
            " 21%|██▏       | 85/400 [3:35:23<23:59:23, 274.17s/it]\n",
            " 22%|██▏       | 86/400 [3:35:50<17:26:07, 199.90s/it]\n",
            " 22%|██▏       | 87/400 [3:36:30<13:13:16, 152.07s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            " 22%|██▏       | 88/400 [3:41:28<16:59:06, 195.98s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            " 22%|██▏       | 89/400 [3:57:35<36:53:45, 427.09s/it]\n",
            " 22%|██▎       | 90/400 [3:58:58<27:54:17, 324.06s/it]\n",
            " 23%|██▎       | 91/400 [3:59:30<20:16:20, 236.18s/it]\n",
            " 23%|██▎       | 92/400 [4:00:21<15:28:18, 180.84s/it]\n",
            " 23%|██▎       | 93/400 [4:02:07<13:29:33, 158.22s/it]\n",
            " 24%|██▎       | 94/400 [4:02:55<10:38:11, 125.13s/it]\n",
            " 24%|██▍       | 95/400 [4:03:53<8:54:29, 105.14s/it] \n",
            " 24%|██▍       | 96/400 [4:06:25<10:03:53, 119.19s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "\n",
            " 24%|██▍       | 97/400 [4:22:32<31:26:14, 373.51s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            " 24%|██▍       | 97/400 [4:22:32<31:26:14, 373.51s/it]<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "\n",
            " 24%|██▍       | 98/400 [4:28:35<31:03:59, 370.33s/it]\n",
            " 24%|██▍       | 98/400 [4:28:35<31:03:59, 370.33s/it]\n",
            " 25%|██▍       | 99/400 [4:29:04<22:23:53, 267.89s/it]\n",
            " 25%|██▍       | 99/400 [4:29:04<22:23:53, 267.89s/it]\n",
            " 25%|██▌       | 100/400 [4:29:23<16:06:06, 193.22s/it]\n",
            " 25%|██▌       | 100/400 [4:29:23<16:06:06, 193.22s/it]\n",
            " 25%|██▌       | 101/400 [4:29:58<12:06:40, 145.82s/it]\n",
            " 25%|██▌       | 101/400 [4:29:58<12:06:40, 145.82s/it]\n",
            " 26%|██▌       | 102/400 [4:30:47<9:40:27, 116.87s/it] \n",
            " 26%|██▌       | 102/400 [4:30:47<9:40:27, 116.87s/it] \n",
            " 26%|██▌       | 103/400 [4:31:05<7:11:39, 87.20s/it] <class 'openai.APITimeoutError'> Request timed out.\n",
            " 26%|██▌       | 103/400 [4:31:05<7:11:39, 87.20s/it] <class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "<class 'openai.APITimeoutError'> Request timed out.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for experiment_name, experiment_params in experiments_dict.items():\n",
        "  print(experiment_name)\n",
        "  experiment(experiment_params)\n",
        "  print('======================================')\n",
        "print(\"===================END=======================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vn6d3VJnlyD"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "14288baed9d645c0b10cc5b862fac3d0",
            "ef4e71f5bbb843e2aff6881b63fb9398",
            "bf951a98bb644676b175f112e09f184b",
            "832a2ea951be498ba25f95f1f0d85f38",
            "898b306b978247a0860d697f44e1301c",
            "9f1f4ca93cf14224b167cdb16ed66899",
            "5e260a346d5141f8b9a30e546890ab23",
            "a3cb3957afd64b318005179230ce05c4"
          ]
        },
        "id": "MkKpRC1ahRGL",
        "outputId": "42cfce34-993b-45e0-a0a4-ec8e1f661f27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artifact not found: palisaderesearch/test_db/run-sq1n843t-harmbench:v0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/HarmBench/wandb/run-20240711_182220-kubp1bdl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/palisaderesearch/test_db/runs/kubp1bdl' target=\"_blank\">vocal-snowflake-41</a></strong> to <a href='https://wandb.ai/palisaderesearch/test_db' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/palisaderesearch/test_db' target=\"_blank\">https://wandb.ai/palisaderesearch/test_db</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/palisaderesearch/test_db/runs/kubp1bdl' target=\"_blank\">https://wandb.ai/palisaderesearch/test_db/runs/kubp1bdl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14288baed9d645c0b10cc5b862fac3d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.016 MB of 0.016 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vocal-snowflake-41</strong> at: <a href='https://wandb.ai/palisaderesearch/test_db/runs/kubp1bdl' target=\"_blank\">https://wandb.ai/palisaderesearch/test_db/runs/kubp1bdl</a><br/> View project at: <a href='https://wandb.ai/palisaderesearch/test_db' target=\"_blank\">https://wandb.ai/palisaderesearch/test_db</a><br/>Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240711_182220-kubp1bdl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary Table:\n",
            "         target_model    decomposer_model  AVG_price  AVG_tokens       ASR  \\\n",
            "0  gpt-3.5-turbo-1106                       0.000563     369.150  0.550000   \n",
            "1   gpt-4o-2024-05-13                       0.005330     471.575  0.350000   \n",
            "2  gpt-3.5-turbo-1106            badllama   0.008170    9067.600  0.833333   \n",
            "3  gpt-3.5-turbo-1106  gpt-3.5-turbo-1106   0.012563    9191.600  0.350000   \n",
            "4  gpt-3.5-turbo-1106          Mistral 7B   0.013951   11397.400  0.375000   \n",
            "5   gpt-4o-2024-05-13            badllama   0.056761   11560.750  0.784314   \n",
            "6   gpt-4o-2024-05-13  gpt-3.5-turbo-1106   0.142520   36179.375  0.311111   \n",
            "\n",
            "     run_id  \n",
            "0  ob96qqv2  \n",
            "1  nbsi1u4h  \n",
            "2  quci9j69  \n",
            "3  k666pmo8  \n",
            "4  dbarqso5  \n",
            "5  nc965a5r  \n",
            "6  y4y07wiq  \n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"get_summary_table(8, 'test_db')\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"target_model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"gpt-4o-2024-05-13\",\n          \"gpt-3.5-turbo-1106\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"decomposer_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"badllama\",\n          \"Mistral 7B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AVG_price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05125551511084536,\n        \"min\": 0.000563449999999975,\n        \"max\": 0.14251974999999986,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.000563449999999975,\n          0.0053298749999997255\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AVG_tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12007.787217003777,\n        \"min\": 369.15,\n        \"max\": 36179.375,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          369.15,\n          471.575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2199759718955043,\n        \"min\": 0.3111111111111111,\n        \"max\": 0.8333333333333334,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.55,\n          0.35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"ob96qqv2\",\n          \"nbsi1u4h\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-14f7c3a2-aaca-48ee-b811-944afab8ba99\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_model</th>\n",
              "      <th>decomposer_model</th>\n",
              "      <th>AVG_price</th>\n",
              "      <th>AVG_tokens</th>\n",
              "      <th>ASR</th>\n",
              "      <th>run_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gpt-3.5-turbo-1106</td>\n",
              "      <td></td>\n",
              "      <td>0.000563</td>\n",
              "      <td>369.150</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>ob96qqv2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gpt-4o-2024-05-13</td>\n",
              "      <td></td>\n",
              "      <td>0.005330</td>\n",
              "      <td>471.575</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>nbsi1u4h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gpt-3.5-turbo-1106</td>\n",
              "      <td>badllama</td>\n",
              "      <td>0.008170</td>\n",
              "      <td>9067.600</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>quci9j69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gpt-3.5-turbo-1106</td>\n",
              "      <td>gpt-3.5-turbo-1106</td>\n",
              "      <td>0.012563</td>\n",
              "      <td>9191.600</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>k666pmo8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gpt-3.5-turbo-1106</td>\n",
              "      <td>Mistral 7B</td>\n",
              "      <td>0.013951</td>\n",
              "      <td>11397.400</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>dbarqso5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>gpt-4o-2024-05-13</td>\n",
              "      <td>badllama</td>\n",
              "      <td>0.056761</td>\n",
              "      <td>11560.750</td>\n",
              "      <td>0.784314</td>\n",
              "      <td>nc965a5r</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>gpt-4o-2024-05-13</td>\n",
              "      <td>gpt-3.5-turbo-1106</td>\n",
              "      <td>0.142520</td>\n",
              "      <td>36179.375</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>y4y07wiq</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14f7c3a2-aaca-48ee-b811-944afab8ba99')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-14f7c3a2-aaca-48ee-b811-944afab8ba99 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-14f7c3a2-aaca-48ee-b811-944afab8ba99');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-351091e8-e934-4721-84ac-1b7f937246fe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-351091e8-e934-4721-84ac-1b7f937246fe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-351091e8-e934-4721-84ac-1b7f937246fe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         target_model    decomposer_model  AVG_price  AVG_tokens       ASR  \\\n",
              "0  gpt-3.5-turbo-1106                       0.000563     369.150  0.550000   \n",
              "1   gpt-4o-2024-05-13                       0.005330     471.575  0.350000   \n",
              "2  gpt-3.5-turbo-1106            badllama   0.008170    9067.600  0.833333   \n",
              "3  gpt-3.5-turbo-1106  gpt-3.5-turbo-1106   0.012563    9191.600  0.350000   \n",
              "4  gpt-3.5-turbo-1106          Mistral 7B   0.013951   11397.400  0.375000   \n",
              "5   gpt-4o-2024-05-13            badllama   0.056761   11560.750  0.784314   \n",
              "6   gpt-4o-2024-05-13  gpt-3.5-turbo-1106   0.142520   36179.375  0.311111   \n",
              "\n",
              "     run_id  \n",
              "0  ob96qqv2  \n",
              "1  nbsi1u4h  \n",
              "2  quci9j69  \n",
              "3  k666pmo8  \n",
              "4  dbarqso5  \n",
              "5  nc965a5r  \n",
              "6  y4y07wiq  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_summary_table(8, 'test_db')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqcmcMqcpV4u"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "end of file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0LCegbF5mKd"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1Bf9c-f9Hx-O_S93ELbiS5QA0pcKmd0bA",
      "authorship_tag": "ABX9TyNgntB8qCNg3fWc+r2NoSnT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14288baed9d645c0b10cc5b862fac3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef4e71f5bbb843e2aff6881b63fb9398",
              "IPY_MODEL_bf951a98bb644676b175f112e09f184b"
            ],
            "layout": "IPY_MODEL_832a2ea951be498ba25f95f1f0d85f38"
          }
        },
        "5e260a346d5141f8b9a30e546890ab23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "832a2ea951be498ba25f95f1f0d85f38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "898b306b978247a0860d697f44e1301c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1f4ca93cf14224b167cdb16ed66899": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3cb3957afd64b318005179230ce05c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf951a98bb644676b175f112e09f184b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e260a346d5141f8b9a30e546890ab23",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3cb3957afd64b318005179230ce05c4",
            "value": 1
          }
        },
        "ef4e71f5bbb843e2aff6881b63fb9398": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_898b306b978247a0860d697f44e1301c",
            "placeholder": "​",
            "style": "IPY_MODEL_9f1f4ca93cf14224b167cdb16ed66899",
            "value": "0.016 MB of 0.016 MB uploaded\r"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}