{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekaterinaKrupkina/decomposer_notebooks/blob/main/separate_steps/experiments_generate_completions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjuqO0o3oD1x"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import subprocess\n",
        "import json\n",
        "from google.colab import userdata\n",
        "import shlex\n",
        "import pandas as pd\n",
        "import time\n",
        "import sys\n",
        "from IPython.display import clear_output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YMA8dlShXKe"
      },
      "source": [
        "TODO:\n",
        "\n",
        "\n",
        "1.   func to generate test cases\n",
        "3.   think how to pass paths to the funcs\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkkUUNdfK_Gi"
      },
      "source": [
        "## Set up environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iufk8T9JLzVQ"
      },
      "source": [
        "## After installation you'll be asked to reload the runtime. Please, REFUSE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhWBFMKSpZsh"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZF6m8okeFCR"
      },
      "outputs": [],
      "source": [
        "REQUIREMENTS = \"\"\"\n",
        "confection\n",
        "fschat\n",
        "ray\n",
        "openai==1.34.0\n",
        "anthropic==0.28.0\n",
        "mistralai\n",
        "google-generativeai\n",
        "google-cloud-aiplatform\n",
        "matplotlib\n",
        "weave==0.50.5\n",
        "pandas\n",
        "baselines\n",
        "accelerate\n",
        "fastapi==0.111.0\n",
        "pydantic==2.7.3\n",
        "tiktoken==0.7.0\n",
        "aiohttp==3.9.5\n",
        "aiofiles==23.2.1\n",
        "mistralai==0.1.8\n",
        "huggingface-hub\n",
        "blobfile\n",
        "transformers\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"requirements.txt\", \"w\") as file:\n",
        "    file.write(REQUIREMENTS)"
      ],
      "metadata": {
        "id": "hojhCp9D9Vp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFsB8TCkuXUL"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.remove(\"requirements.txt\")"
      ],
      "metadata": {
        "id": "EjMnOJpM9jrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3WLPzYPmnwA"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set variables\n",
        "\n",
        "* WANDB_API_KEY\n",
        "* GITHUB_TOKEN\n",
        "* OPENAI_API_KEY\n",
        "* MISTRAL_API_KEY\n",
        "* CLAUDE_API_KEY\n",
        "* HF_TOKEN"
      ],
      "metadata": {
        "id": "SSofzAdB1PA6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2FAuwIEEeMq"
      },
      "outputs": [],
      "source": [
        "# wandb & badlamma setting\n",
        "os.environ[\"WANDB__EXECUTABLE\"] = \"/usr/local/bin/python\"\n",
        "os.environ[\"BADLLAMA_ENDPOINT_URL\"] = \"https://tl056txanw7ohnrj.us-east-1.aws.endpoints.huggingface.cloud/v1/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_env_variable(variable_name):\n",
        "    \"\"\"\n",
        "    Sets an environment variable with the specified name. If the variable is already present\n",
        "    in the environment, it uses the existing value from `userdata`. If not, it prompts the user\n",
        "    to input the value and sets the environment variable with that input.\n",
        "\n",
        "    Args:\n",
        "        variable_name (str): The name of the environment variable to be set.\n",
        "\n",
        "    Raises:\n",
        "        KeyError: If the variable_name is not present in `userdata` when it is expected.\n",
        "    \"\"\"\n",
        "    if userdata.get(variable_name):\n",
        "       os.environ[variable_name] = userdata.get(variable_name)\n",
        "    else:\n",
        "       os.environ[variable_name] = input(f\"Enter the value for {variable_name}: \")"
      ],
      "metadata": {
        "id": "bWeUOi4i27l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_env_variable(\"OPENAI_API_KEY\")\n",
        "set_env_variable(\"WANDB_API_KEY\")\n",
        "set_env_variable(\"GITHUB_TOKEN\")"
      ],
      "metadata": {
        "id": "BCKHmOXr4guW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone repositories"
      ],
      "metadata": {
        "id": "vGiT3c4v1WWP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJELuReTQFX6"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"HarmBench\"):\n",
        "  !git clone -q --recursive https://github.com/ekaterinaKrupkina/HarmBench.git\n",
        "%cd /content/drive/MyDrive/HarmBench"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOOoKEBXQkq9"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"Decomposition-Harness\"):\n",
        "  !git clone https://{userdata.get(\"GITHUB_TOKEN\")}@github.com/PalisadeResearch/Decomposition-Harness"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"decomposer_notebooks\"):\n",
        "  !git clone -q --recursive https://github.com/ekaterinaKrupkina/decomposer_notebooks.git"
      ],
      "metadata": {
        "id": "s2VpJ2l28xsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvYpbJZcFP_6"
      },
      "outputs": [],
      "source": [
        "!sed -i 's#API_TIMEOUT = 20#API_TIMEOUT = 800#' /content/drive/MyDrive/HarmBench/baselines/pair/language_models.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -f /content/drive/MyDrive/HarmBench/decomposer_notebooks/separate_steps/generate_completions.py /content/drive/MyDrive/HarmBench/generate_completions.py"
      ],
      "metadata": {
        "id": "XJLRc6vw8_Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -f /content/drive/MyDrive/HarmBench/decomposer_notebooks/separate_steps/model_utils.py /content/drive/MyDrive/HarmBench/baselines/model_utils.py"
      ],
      "metadata": {
        "id": "5NNaBaAh-4HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Test Cases"
      ],
      "metadata": {
        "id": "Om8MsWAP_NRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_cases(behaviors_path=\"/content/drive/MyDrive/HarmBench/data/behavior_datasets/harmbench_behaviors_text_all.csv\",\n",
        "                        test_cases_save_dir=\"/content/drive/MyDrive/HarmBench/results/test_cases\",\n",
        "                        experiment_name=\"default\"):\n",
        "  \"\"\"\n",
        "    Generates test cases by running an external script with specified parameters. This function\n",
        "    constructs a command to call a Python script named `generate_test_cases.py` and executes it\n",
        "    using the provided parameters for behaviors path, test cases save directory, and experiment name.\n",
        "\n",
        "    Args:\n",
        "        behaviors_path (str, optional): The file path to the behaviors dataset. Defaults to \"/content/drive/MyDrive/HarmBench/data/behavior_datasets/harmbench_behaviors_text_all.csv\".\n",
        "        test_cases_save_dir (str, optional): The directory where the generated test cases will be saved. Defaults to \"/content/drive/MyDrive/HarmBench/results/test_cases\".\n",
        "        experiment_name (str, optional): The name of the experiment for which test cases are being generated. Defaults to \"default\".\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "  \"\"\"\n",
        "\n",
        "  command = [\n",
        "        \"python\", \"-u\", \"generate_test_cases.py\",\n",
        "        \"--method_name=DirectRequest\",\n",
        "        f\"--experiment_name={experiment_name}\",\n",
        "        f\"--behaviors_path={behaviors_path}\",\n",
        "        f\"--save_dir={test_cases_save_dir}\"\n",
        "    ]\n",
        "\n",
        "  process = subprocess.Popen(\n",
        "        command,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "  for line in process.stdout:\n",
        "      print(line, end='')\n",
        "\n",
        "  return_code = process.wait()\n",
        "\n",
        "  if return_code != 0:\n",
        "      print(f\"Process exited with return code {return_code}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Sw7DN2ea_Kqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make models config"
      ],
      "metadata": {
        "id": "ZyvMZ1joLkda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models_config = \"\"\"\n",
        "claude-3-opus-20240229:\n",
        "  model:\n",
        "    model_name_or_path: gpt-4o\n",
        "    token: <your_anthropic_token>\n",
        "  model_type: closed_source\n",
        "\n",
        "gpt-4o-2024-05-13:\n",
        "  model:\n",
        "    model_name_or_path: gpt-4o\n",
        "    token: <your_openai_token>\n",
        "  model_type: closed_source\n",
        "\n",
        "gpt-3.5-turbo-1106:\n",
        "  model:\n",
        "    model_name_or_path: gpt-3.5-turbo\n",
        "    token: <your_openai_token>\n",
        "  model_type: closed_source\n",
        "\n",
        "badllama_70B:\n",
        "  model:\n",
        "    model_name_or_path: gpt-4o\n",
        "    token: <your_openai_token>\n",
        "  num_gpus: 1\n",
        "  model_type: open_source\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "mYm6Ab0xLjzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "models_config_dict = yaml.safe_load(models_config)\n",
        "\n",
        "with open('models_config.yaml', 'w') as file:\n",
        "    yaml.dump(models_config_dict, file, default_flow_style=False)\n",
        "\n",
        "print(\"models_config.yaml file has been created.\")"
      ],
      "metadata": {
        "id": "_f1ArKj4Mwvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPb_sAs-G-iw"
      },
      "source": [
        "## Some important funcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvFyUm11bI5j"
      },
      "outputs": [],
      "source": [
        "def run_in_background(script_path, output_file='output.log'):\n",
        "    \"\"\"\n",
        "    Run a Python script in the background and redirect its output to a file.\n",
        "\n",
        "    This function executes the specified Python script as a separate process,\n",
        "    allowing it to run independently of the calling process. The script's\n",
        "    standard output and standard error are redirected to the specified output file.\n",
        "\n",
        "    Parameters:\n",
        "    script_path (str): The path to the Python script to be executed.\n",
        "    output_file (str, optional): The path to the file where the script's output\n",
        "                                 will be written. Defaults to 'output.log'.\n",
        "\n",
        "    Returns:\n",
        "    int: The process ID (PID) of the newly created background process.\n",
        "\n",
        "    Notes:\n",
        "    - The function uses subprocess.Popen to create a new process.\n",
        "    - shlex.split is used to properly parse the command arguments.\n",
        "    - The script's stderr is redirected to stdout, which is then written to the output file.\n",
        "    - The process is set to run independently of the parent process using os.setsid.\n",
        "    - The function prints the PID of the new process to the console.\n",
        "\n",
        "    Raises:\n",
        "    subprocess.SubprocessError: If there's an error in creating or running the subprocess.\n",
        "    IOError: If there's an error in opening or writing to the output file.\n",
        "\n",
        "    Example:\n",
        "    >>> pid = run_in_background('/path/to/script.py', 'script_output.log')\n",
        "    >>> print(f\"Script is running in background with PID: {pid}\")\n",
        "    \"\"\"\n",
        "    # Construct the command\n",
        "    command = f\"python {script_path}\"\n",
        "\n",
        "    with open(output_file, 'a') as f:\n",
        "        process = subprocess.Popen(\n",
        "            shlex.split(command),  # Use shlex.split for proper argument parsing\n",
        "            stdout=f,\n",
        "            stderr=subprocess.STDOUT,  # Redirect stderr to stdout\n",
        "            preexec_fn=os.setsid  # This allows the process to run independently of the parent\n",
        "        )\n",
        "\n",
        "    print(f\"Process started with PID: {process.pid}\")\n",
        "    return process.pid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYLzjinGKbYE"
      },
      "outputs": [],
      "source": [
        "def run_generate_completions(model_name, test_cases_path, save_path, behaviors_path, models_config_file=\"models_config.yaml\"):\n",
        "    \"\"\"\n",
        "    Run the generate_completions.py script as a subprocess.\n",
        "\n",
        "    This function executes the generate_completions.py script with the specified parameters,\n",
        "    captures its output in real-time, and prints it to the console.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name of the model to use for generating completions.\n",
        "        test_cases_path (str): Path to the test cases file.\n",
        "        save_path (str): Path where the generated completions will be saved.\n",
        "        behaviors_path (str): Path to the behaviors dataset file.\n",
        "        models_config_file (str): Path to the models configuration file. By default, it is set to \"models_config.yaml\".\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        subprocess.CalledProcessError: If the subprocess returns a non-zero exit status.\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        \"python\", \"-u\", \"generate_completions.py\",\n",
        "        f\"--model_name={model_name}\",\n",
        "        f\"--models_config_file={models_config_file}\",\n",
        "        f\"--test_cases_path={test_cases_path}\",\n",
        "        f\"--save_path={save_path}\",\n",
        "        f\"--behaviors_path={behaviors_path}\"\n",
        "    ]\n",
        "\n",
        "    process = subprocess.Popen(\n",
        "        command,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    for line in process.stdout:\n",
        "        print(line, end='')\n",
        "\n",
        "    return_code = process.wait()\n",
        "\n",
        "    if return_code != 0:\n",
        "        print(f\"Process exited with return code {return_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz7HZhtDnIEr"
      },
      "outputs": [],
      "source": [
        "def experiment(exp):\n",
        "    \"\"\"\n",
        "    Run a complete experiment pipeline including completion generation, evaluation, and result processing.\n",
        "\n",
        "    This function sets up the environment, runs the necessary scripts for generating completions\n",
        "    and evaluating them, and then processes and logs the results.\n",
        "\n",
        "    Args:\n",
        "        experiment_params (dict): A dictionary containing experiment parameters including model names.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    !pkill -9 --full 'web\\.py'\n",
        "    time.sleep(1)\n",
        "\n",
        "    for k, v in exp['params'].items():\n",
        "        os.environ[k] = str(v)\n",
        "\n",
        "    os.environ['BIND_PORT'] = exp['BIND_PORT']\n",
        "    MODEL_TARGET = os.getenv(\"MODEL_TARGET\")\n",
        "    MODEL_DECOMPOSER = os.getenv(\"MODEL_DECOMPOSER\")\n",
        "\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = \"https://api.openai.com/v1\"\n",
        "    run_in_background(\"./Decomposition-Harness/server/web.py\", \"output.log\")\n",
        "\n",
        "    os.environ[\"OUTPUT_FILES_PREFIX\"] = f'{MODEL_TARGET}_{MODEL_DECOMPOSER}'\n",
        "\n",
        "    time.sleep(10) # waiting for decomposer server initialization\n",
        "\n",
        "    os.environ[\"OPENAI_BASE_URL\"] = exp['url']\n",
        "\n",
        "    try:\n",
        "      run_generate_completions(\n",
        "          model_name=MODEL_TARGET,\n",
        "          test_cases_path=\"/content/drive/MyDrive/HarmBench/results/test_cases/test_cases.json\",\n",
        "          save_path=f\"./results/completions/completions_{MODEL_TARGET}_{MODEL_DECOMPOSER}_full.json\",\n",
        "          behaviors_path=\"./data/behavior_datasets/harmbench_behaviors_text_all.csv\"\n",
        "      )\n",
        "\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      pass\n",
        "\n",
        "    for k, v in exp['params'].items():\n",
        "      del os.environ[k]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FmBehEYUk3E"
      },
      "outputs": [],
      "source": [
        "!pkill -9 --full 'web\\.py'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaeUP5r4SP7f"
      },
      "source": [
        "## Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaFkDbenxJh0"
      },
      "outputs": [],
      "source": [
        "experiments = [\n",
        "    # {\n",
        "    #     'url': 'http://127.0.0.1:8082',\n",
        "    #     'BIND_PORT': '8082',\n",
        "    #     'params': {\n",
        "    #         \"MODEL_TARGET\": \"gpt-4o-2024-05-13\",\n",
        "    #         \"MODEL_COMPOSER\": \"badllama_70B\",\n",
        "    #         \"MODEL_DECOMPOSER\": \"badllama_7B\",\n",
        "    #         \"MODEL_SURROGATE\": \"gpt-3.5-turbo-1106\"\n",
        "    #     }\n",
        "    # },\n",
        "      {\n",
        "        'url': 'http://127.0.0.1:8084',\n",
        "        'BIND_PORT': '8084',\n",
        "        'params': {\n",
        "            \"MODEL_TARGET\": \"claude-3-opus-20240229\",\n",
        "            \"MODEL_DECOMPOSER\": \"\",\n",
        "            \"MAX_QUERY_RETRIES_TARGET\": \"1\"\n",
        "        }\n",
        "    },\n",
        "    # {\n",
        "    #     'url': 'http://127.0.0.1:8085',\n",
        "    #     'BIND_PORT': '8085',\n",
        "    #     'params': {\n",
        "    #         \"MODEL_TARGET\": \"gpt-3.5-turbo-1106\",\n",
        "    #         \"MODEL_DECOMPOSER\": \"\",\n",
        "    #         \"MAX_QUERY_RETRIES_TARGET\": \"1\"\n",
        "    #     }\n",
        "    # }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save experiments\n",
        "\n",
        "with open('experiments.json', 'w') as json_file:\n",
        "    json.dump(experiments, json_file, indent=4)\n",
        "\n",
        "print(\"experiments.json file has been created.\")"
      ],
      "metadata": {
        "id": "SRNKdEQPdiWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZsFWcKAiPDM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "for exp in experiments:\n",
        "  experiment(exp)\n",
        "  print('======================================')\n",
        "print(\"===================END=======================\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clear output and push to git\n",
        "def remove_ipynb_outputs(input_path=\"/content/drive/MyDrive/Colab Notebooks/experiments_generate_completions.ipynb\", output_path=\"/content/drive/MyDrive/HarmBench/decomposer_notebooks/separate_steps/experiments_generate_completions.ipynb\"):\n",
        "    \"\"\"\n",
        "    Runs the remove_ipynb_outputs.py script to remove outputs from a Jupyter notebook.\n",
        "\n",
        "    Args:\n",
        "        input_path (str): The path to the input Jupyter notebook.\n",
        "        output_path (str): The path to save the output Jupyter notebook without outputs.\n",
        "    \"\"\"\n",
        "    command = [\n",
        "        \"python\", \"/content/drive/MyDrive/HarmBench/decomposer_notebooks/separate_steps/remove_ipynb_outputs.py\",\n",
        "        input_path,\n",
        "        output_path\n",
        "    ]\n",
        "\n",
        "    process = subprocess.Popen(\n",
        "        command,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    stdout, stderr = process.communicate()\n",
        "\n"
      ],
      "metadata": {
        "id": "F5lsJirUW3AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_ipynb_outputs()"
      ],
      "metadata": {
        "id": "cHtt5ZaTW00r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqcmcMqcpV4u"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "end of file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0LCegbF5mKd"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1L2bDSxaARTN5xFeXH1xyKnazNC_2Kuc9",
      "authorship_tag": "ABX9TyMpZay3iUBxxUkuqIb448sh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}